# 重叠音频场景下的乐器识别研究



## 一、项目概述

​	本项目针对重叠音频场景中的乐器识别问题，提出了一种融合 U-Net 和 ResNet 的联合模型，通过端到端的协同优化实现音频分离与分类任务，提升复杂混合场景下的乐器识别准确率。





## 二、环境配置

### 依赖库

```
torch>=2.0.0        
librosa>=0.10.0  
soundfile>=0.12.0 
numpy>=1.26.0  
scikit-image>=0.21.0 
torchvision>=0.15.0  
tqdm>=4.65.0 
```



## 三、数据集构建

### 数据准备

1.  **单乐器音频库**

*   结构：在`raw_data/`目录下创建各乐器类别文件夹（如`piano/`、`guitar/`），每个文件夹包含至少 2000 个单乐器音频片段（`.wav`格式）。


*   要求：采样率为 16kHz，单声道，时长建议≥2 秒。


### 生成混合音频数据集

运行`01.py`脚本生成混合音频样本及标签：


```
python 01.py
```

*   **参数说明**
*    `data_dir`: 单乐器音频根目录（默认`./raw_data/`）。
*    `output_dir`: 输出目录（默认`./train_data/`）。
*    `samples_per_combination`: 每个乐器组合生成的样本数（默认 2000，总样本数 = 组合数 × 该值）。




*   **输出结果**
*   在`output_dir`下生成：

    *   `sample_xxx/`目录：包含`mixed.wav`（混合音频）、`source1.wav`和`source2.wav`（分离源音频）。
    *   `labels.txt`：标签文件，格式为`混合音频路径 源1路径 源2路径 标签1 标签2`。





## 四、模型训练

### 数据预处理

*   **特征提取**：使用梅尔频谱变换将音频转换为 128×128 的时频图，归一化到 \[0,1] 区间。


*   **数据集划分**：自动按 8:2 比例划分训练集和测试集。




### 训练流程

运行`02.py`脚本启动训练：


```
python 02.py
```



### 关键参数

| 参数名          | 说明&#xA;                                           |
| --------------- | --------------------------------------------------- |
| `batch_size`    | 批量大小，默认 64（可根据 GPU 内存调整）            |
| `epochs`        | 训练轮数，默认 30                                   |
| `learning_rate` | 初始学习率，默认 0.0015                             |
| `weight_decay`  | L2 正则化系数，默认 1e-4                            |
| `loss_weight`   | 分离损失与分类损失权重，默认`0.7*L_sep + 0.3*L_cls` |



### 训练监控

*   控制台实时显示训练进度、损失值（Loss）和准确率（Acc）。


*   训练完成后保存模型参数到`logs/m2.pth`。





## 五、评估指标



*   **分类准确率**：正确识别的乐器类别占比。


*   **均方误差（MSE）**：分离频谱与原始频谱的重建误差。





## 六、项目结构



```
project/

├─ raw\_data/          # 单乐器音频库（用户需自行准备）

├─ train\_data/        # 生成的混合音频数据集

│  ├─ sample\_xxx/

│  └─ labels.txt       # 数据集标签

├─ logs/               # 训练日志及模型参数

├─ 01.py               # 混合音频生成脚本
 
└─ 02.py               # 模型定义与训练脚本
```





## 七、注意事项



1.  **数据规模**：建议至少包含 5 种乐器（如钢琴、吉他、小提琴等），总样本数≥20000 以保证模型泛化能力。


2.  **GPU 支持**：训练过程需 GPU 加速（推荐 NVIDIA 显卡，配置 CUDA 环境）。


3.  **超参数调整**：可通过修改`02-3.py`中的`loss_weight`（λ）、学习率策略等优化模型性能。
